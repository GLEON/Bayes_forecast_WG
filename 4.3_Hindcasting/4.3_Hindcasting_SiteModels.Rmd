---
title: "Dietze Ch. 11 Uncertainty Analysis-Copy"
author: "J. Brentrup"
date: "6/28/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load libraries
```{r}
library(ecoforecastR)
pacman::p_load(tidyverse, readxl, rjags, runjags, moments, coda)

```

## Load all site gloeo data for full time series
```{r}
gloeo <- read_csv("./00_Data_files/Bayesian_model_input_data/Gloeo_AllSites.csv")
  
```


## Load Data for Model Runs

```{r, echo=FALSE}
# Single site HC - stop @ 2014

# Source Functions
  source('0_Function_library/hindcasting_get_data_site.R') #check correct script sourced
  source('0_Function_library/model_hindcasting_plug_n_play_site.R')

# Get model
my_models <- c("DLM_1site") #,"RW_obs_1site", "DLM_1site","wtrtemp_min_and_GDD_1site", "wtrtemp_min_and_GDD_1site_RY", "wtrtemp_min_and_airtempGDD_1site_RY_HC"

model_name = my_models
model=paste0("4.1_JAGS_models/",model_name, '.R') #Do not edit

# Read in data for model
hindcast_data <- get_hindcast_data(model_name = model_name)
# hindcast_data_hc <- get_hindcast_data(model_name = model_name)
# hindcast_data_nb <- get_hindcast_data(model_name = model_name)
# hindcast_data_nsh <- get_hindcast_data(model_name = model_name)

# JAGS Plug-Ins => initial conditions, priors, data, etc.
jags_plug_ins <- jags_plug_ins(model_name = model_name)

# Run model (no edits, unless you want to change # of iterations)
j.model   <- jags.model (file = model,
                         data = jags_plug_ins$data.model,
                         inits = jags_plug_ins$init.model,
                         n.chains = 3)
# jags
jags.out <- run.jags(model = model,
                     data = jags_plug_ins$data.model,
                     adapt =  5000, # not the same as thinning - Mary: Thinned to 7,500 samples for hindcasting and model assessment
                     burnin =  10000,
                     sample = 50000, #50000
                     n.chains = 3,
                     inits=jags_plug_ins$init.model,
                     monitor = jags_plug_ins$variable.namesout.model)

#convert to an MCMC list to calculate cross-correlation later
jags.out.mcmc <- as.mcmc.list(jags.out)


#6) Save output for calibration assessment

#save predicted states
Nmc = 10000
out <- as.matrix(jags.out.mcmc) # Window to thin, burn-in,

srow <- sample.int(nrow(out),Nmc,replace=TRUE)
mus <- out[srow,grep("mu",colnames(out))]
betas <- out[srow, grep("beta",colnames(out))]
taus <- out[srow, grep("tau",colnames(out))]
params_init <- cbind(betas, taus)

covar1_ensemble <- out[srow, grep("covar1",colnames(out))]
covar2_ensemble <- out[srow, grep("covar2",colnames(out))]

# Ensemble
out_hc <- out
out_nb <- out
out_nsh <- out

out_all <- cbind(out_hc, out_nb, out_nsh)
 mu.cols <- grep("^mu",colnames(out_all)) # out ## grab all columns that start with the letter mu

mu_ensemble <- apply(out_all[,mu.cols],1,mean) ## model was fit on log scale but keep in log scale

mu_ensemble_col <- apply(out_all[,mu.cols],2,mean) ## model was fit on log scale but keep in log scale

srow_v2 <- sample.int(nrow(out_all),Nmc,replace=TRUE)

mus_v2 <- mu_ensemble[srow_v2,grep("mu",colnames(out_all))]

nrow(out)
```


### Posterior Diagnostics

As noted earlier, we're going to take the fitting of this model to the data as a given, and work with the posterior distributions, but if you are unsure about how this is done please go back and look at Exercises 5 and 6 and the Chapter 6 activities. Here are the basic diagnostics showing the posterior estimates of the parameters and states.

# check histograms
```{r}
hist(mus)
median(mus)
max(mus)
mean(mus)
hist(mus_v2)
```


## Check Model Run
```{r}
y = hindcast_data$y
time = hindcast_data$season_weeks # for full time series
#time = date # for 2013
time.rng = c(1,length(time))       ## adjust to zoom in and out
#time.rng = c(321,480)              ## zoom in on 2013: 81-100, 2015-2016: 121-160, 141-160 - 2016
time2 = 121:140   ## forecast period
#out <- as.matrix(jags.out)         ## convert from coda to matrix  
mu.cols <- grep("^mu",colnames(out)) # out ## grab all columns that start with the letter mu

ci <- apply(out[,mu.cols],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale but keep in log scale

plot(time,ci[2,],type='n',ylim=range(ci,na.rm=TRUE),ylab="LN Gloeo", xlab = "Week", xlim=time[time.rng]) #, xaxt = "n") #, xaxt = "n"#log='y', don't need on log scale
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='week'), format = "%Y-%m-%d", labels = T)
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha(5,0.5))
lines(time,y)
points(time,y,pch=19,cex=1.25, col = 3) #0.5, pch="+",
points(time, y, cex = 1)
lines(time, ci[2,], lty = 2)
#lines(time, ci[3,], lty = 2)
points(time, ci[2,], col = 6, pch=19, cex = 1)
#points(time, ci[2,], cex = 1) # black outline

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 1.25, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015.png'))), type = "png")

# Add in 2015 data HC
time2 = 121:140   ## forecast period

lines(time2, gloeo$hc_gloeo_ln[121:140])
points(time2, gloeo$hc_gloeo_ln[121:140], pch=19,cex=1.25, col = 3)

# Add in 2015 data NB
lines(time2, gloeo$nb_gloeo_ln[121:140])
points(time2, gloeo$nb_gloeo_ln[121:140], pch=19,cex=1.25, col = 3)

# Add in 2015 data NSH
lines(time2, gloeo$nsh_gloeo_ln[121:140])
points(time2, gloeo$nsh_gloeo_ln[121:140], pch=19,cex=1.25, col = 3)


# Add data in for 2015
quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015_data2015.png'))), type = "png")



```


## Check model run with Fichter
```{r}

ylim = range(ci,na.rm=TRUE) 
#ylim = c(-7.008481, 4) ## set Y range on plot - too short for NSH

plot(time,time,type='n',ylim=ylim,ylab="LN Gloeo", xlab = "Week", main = "Fichter with NSH Model")
  ecoforecastR::ciEnvelope(time2,ci[1,121:140],ci[3,121:140],col=col.alpha(5,0.5))
  lines(time,gloeo$sotf_gloeo_ln[1:140])
  points(time,gloeo$sotf_gloeo_ln[1:140],pch=19,cex=1.25, col = 3)
  points(time,gloeo$sotf_gloeo_ln[1:140],cex = 1)
  lines(time2, ci[2,121:140], lty = 2)
  points(time2, ci[2,121:140], col = 6, pch=19, cex = 1)

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 1.25, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('SOTF_',model_name,'_Obs_vs_pred2015_data2015.png'))), type = "png")

```

## Herrick Cove Plots
```{r}
# Get data from gloeo data in data viz

gloeo_final_site <- gloeo_final %>% 
  filter(site == "HerrickCoveSouth") %>% 
  filter(year != 2016)

y = hindcast_data_hc$y
time = hindcast_data_hc$season_weeks # for full time series
time.rng = c(1,length(time))       ## adjust to zoom in and out
#time.rng = c(321,480)              ## zoom in on 2013: 81-100, 2015-2016: 121-160, 141-160 - 2016
#out <- as.matrix(jags.out)         ## convert from coda to matrix  
# mu.cols <- grep("^mu",colnames(out)) # out ## grab all columns that start with the letter mu
# 
# ci <- apply(out[,mu.cols],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale but keep in log scale

#Dates on x-axis, plots entire year
time = gloeo_final_site$date # for 2013

plot(time,hc_ci[2,],type='n',ylim=range(hc_ci,na.rm=TRUE), xlim=time[time.rng],
     ylab="Natural Log G. echinulata (colonies/L)", xlab = "",
     main = "Herrick Cove", xaxt = "n") #, xaxt = "n"#log='y', don't need on log scale
if(diff(time.rng) < 150){
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "year"), format = "%Y") #, labels = T)
}

range(hc_ci) # [1] -7.008958  4.415712
range(nb_ci) #-8.230718  4.444704

plot(time,hc_ci[2,],type='n',ylim=range(nb_ci,na.rm=TRUE), xlim=time[time.rng], 
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "Herrick Cove") 
ecoforecastR::ciEnvelope(time,hc_ci[1,],hc_ci[3,],col=ecoforecastR::col.alpha(5,0.5))
lines(time,y, lwd = 1.5)
points(time,y,pch=19,cex=1.5, col = 3) #0.5, pch="+",
points(time, y, cex = 1.5)
lines(time, hc_ci[2,], lty = 2, lwd = 2)
#lines(time, ci[3,], lty = 2)
points(time, hc_ci[2,], col = 6, pch=19, cex = 1.35)
#points(time, ci[2,], cex = 1) # black outline

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 1.25, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)

# Add in 2015 data HC
lines(time2, gloeo$hc_gloeo_ln[121:140], lwd = 1.5)
points(time2, gloeo$hc_gloeo_ln[121:140], pch=19,cex=1.5, col = 3)

# Add in 2015 data NB
lines(time2, gloeo$nb_gloeo_ln[121:140])
points(time2, gloeo$nb_gloeo_ln[121:140], pch=19,cex=1.25, col = 3)

# Add in 2015 data NSH
lines(time2, gloeo$nsh_gloeo_ln[121:140])
points(time2, gloeo$nsh_gloeo_ln[121:140], pch=19,cex=1.25, col = 3)


# Add data in for 2015
quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015_data2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)



```

## HC with Fichter
```{r}

gloeo_final_site <- gloeo_final %>% 
  filter(site == "SouthOfTheFells") %>% 
  filter(year == 2015)

time.rng = c(1,length(time2))       ## adjust to zoom in and out
time = gloeo_final_site$date

plot(time,hc_ci[2,121:140],type='n',ylim=range(nb_ci,na.rm=TRUE),
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "South of the Fells Prediction \n with Herrick Cove Model")
if(diff(time.rng) < 150){
axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "2 weeks"), format = "%d-%b", labels = T, cex.axis = 1.5)
}
  ecoforecastR::ciEnvelope(time,hc_ci[1,121:140],hc_ci[3,121:140],col=col.alpha(5,0.5))
  lines(time,gloeo$sotf_gloeo_ln[121:140], lwd = 1.5)
  points(time,gloeo$sotf_gloeo_ln[121:140],pch=19,cex=2.5, col = 3)
  points(time,gloeo$sotf_gloeo_ln[121:140],cex = 2.5)
  lines(time, hc_ci[2,121:140], lty = 2, lwd = 2)
  points(time, hc_ci[2,121:140], col = 6, pch=19, cex = 2.35)

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 2, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('SOTF_',model_name,'_Obs_vs_pred2015_data2015.pdf'))),type = "pdf", dpi = 600) #, width = 8.5, height = 11)

```

## Newbury Plots
```{r}

y = hindcast_data_nb$y
time = hindcast_data_nb$season_weeks # for full time series
time.rng = c(1,length(time))       ## adjust to zoom in and out
#time.rng = c(321,480)              ## zoom in on 2013: 81-100, 2015-2016: 121-160, 141-160 - 2016
#out <- as.matrix(jags.out)         ## convert from coda to matrix  
# mu.cols <- grep("^mu",colnames(out)) # out ## grab all columns that start with the letter mu
# 
# ci <- apply(out[,mu.cols],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale but keep in log scale

# Dates on x-axis, plots entire year
# time = gloeo_final_site$date # for 2013
# 
# plot(time,hc_ci[2,],type='n',ylim=range(hc_ci,na.rm=TRUE), xlim=time[time.rng], 
#      ylab="Natural Log G. echinulata (colonies/L)", xlab = "",  
#      main = "Herrick Cove", xaxt = "n") #, xaxt = "n"#log='y', don't need on log scale
# if(diff(time.rng) < 150){
#   axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "year"), format = "%Y") #, labels = T)
# }

range(hc_ci) # [1] -7.008958  4.415712
range(nb_ci) #-8.230718  4.444704

plot(time,nb_ci[2,],type='n',ylim=range(nb_ci,na.rm=TRUE), xlim=time[time.rng], 
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "Newbury") 
ecoforecastR::ciEnvelope(time,nb_ci[1,],nb_ci[3,],col=ecoforecastR::col.alpha(5,0.5))
lines(time,y, lwd = 1.5)
points(time,y,pch=19,cex=1.5, col = 3) #0.5, pch="+",
points(time, y, cex = 1.5)
lines(time, nb_ci[2,], lty = 2, lwd = 2)
#lines(time, ci[3,], lty = 2)
points(time, nb_ci[2,], col = 6, pch=19, cex = 1.35)
#points(time, ci[2,], cex = 1) # black outline

legend("bottomleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 1.25, bty = "n")

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)


# Add in 2015 data NB
lines(time2, gloeo$nb_gloeo_ln[121:140], lwd = 1.5)
points(time2, gloeo$nb_gloeo_ln[121:140], pch=19,cex=1.5, col = 3)

# Save plot with data for 2015
quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015_data2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)



```

## NB with Fichter
```{r}

gloeo_final_site <- gloeo_final %>% 
  filter(site == "SouthOfTheFells") %>% 
  filter(year == 2015)

time.rng = c(1,length(time2))       ## adjust to zoom in and out
time = gloeo_final_site$date

plot(time,nb_ci[2,121:140],type='n',ylim=range(nb_ci,na.rm=TRUE),
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "South of the Fells Prediction \n with Newbury Model")
if(diff(time.rng) < 150){
axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "2 weeks"), format = "%d-%b", labels = T, cex.axis = 1.5)
}
  ecoforecastR::ciEnvelope(time,nb_ci[1,121:140],nb_ci[3,121:140],col=col.alpha(5,0.5))
  lines(time,gloeo$sotf_gloeo_ln[121:140], lwd = 1.5)
  points(time,gloeo$sotf_gloeo_ln[121:140],pch=19,cex=2.5, col = 3)
  points(time,gloeo$sotf_gloeo_ln[121:140],cex = 2.5)
  lines(time, nb_ci[2,121:140], lty = 2, lwd = 2)
  points(time, nb_ci[2,121:140], col = 6, pch=19, cex = 2.35)

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 2, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('SOTF_',model_name,'_Obs_vs_pred2015_data2015.pdf'))),type = "pdf", dpi = 600) #, width = 8.5, height = 11)

```

## Coffin Plots
```{r}

y = hindcast_data_nsh$y
time = hindcast_data_nsh$season_weeks # for full time series
time.rng = c(1,length(time))       ## adjust to zoom in and out
#time.rng = c(321,480)              ## zoom in on 2013: 81-100, 2015-2016: 121-160, 141-160 - 2016
#out <- as.matrix(jags.out)         ## convert from coda to matrix  
# mu.cols <- grep("^mu",colnames(out)) # out ## grab all columns that start with the letter mu
# 
# ci <- apply(out[,mu.cols],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale but keep in log scale

# Dates on x-axis, plots entire year
# time = gloeo_final_site$date # for 2013
# 
# plot(time,hc_ci[2,],type='n',ylim=range(hc_ci,na.rm=TRUE), xlim=time[time.rng], 
#      ylab="Natural Log G. echinulata (colonies/L)", xlab = "",  
#      main = "Herrick Cove", xaxt = "n") #, xaxt = "n"#log='y', don't need on log scale
# if(diff(time.rng) < 150){
#   axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "year"), format = "%Y") #, labels = T)
# }

range(hc_ci) # [1] -7.008958  4.415712
range(nb_ci) #-8.230718  4.444704

plot(time,nsh_ci[2,],type='n',ylim=range(nb_ci,na.rm=TRUE), xlim=time[time.rng], 
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "North Sunapee Harbor") 
ecoforecastR::ciEnvelope(time,nsh_ci[1,],nsh_ci[3,],col=ecoforecastR::col.alpha(5,0.5))
lines(time,y, lwd = 1.5)
points(time,y,pch=19,cex=1.5, col = 3) #0.5, pch="+",
points(time, y, cex = 1.5)
lines(time, nsh_ci[2,], lty = 2, lwd = 2)
#lines(time, ci[3,], lty = 2)
points(time, nsh_ci[2,], col = 6, pch=19, cex = 1.35)
#points(time, ci[2,], cex = 1) # black outline

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 1.25, bty = "n")

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)

# Add in 2015 data NSH
lines(time2, gloeo$nsh_gloeo_ln[121:140], lwd = 1.5)
points(time2, gloeo$nsh_gloeo_ln[121:140], pch=19,cex=1.5, col = 3)


# Add data in for 2015
quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015_data2015.pdf'))), type = "pdf", family = "Helvetica", dpi = 600, width = 11, height = 8.5)



```

## NSH with Fichter
```{r}

gloeo_final_site <- gloeo_final %>% 
  filter(site == "SouthOfTheFells") %>% 
  filter(year == 2015)

time.rng = c(1,length(time2))       ## adjust to zoom in and out
time = gloeo_final_site$date

plot(time,nsh_ci[2,121:140],type='n',ylim=range(nb_ci,na.rm=TRUE),
     xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "South of the Fells Prediction \n with North Sunapee Harbor Model")
if(diff(time.rng) < 150){
axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]], by = "2 weeks"), format = "%d-%b", labels = T, cex.axis = 1.5)
}
  ecoforecastR::ciEnvelope(time,nsh_ci[1,121:140],nsh_ci[3,121:140],col=col.alpha(5,0.5))
  lines(time,gloeo$sotf_gloeo_ln[121:140], lwd = 1.5)
  points(time,gloeo$sotf_gloeo_ln[121:140],pch=19,cex=2.5, col = 3)
  points(time,gloeo$sotf_gloeo_ln[121:140],cex = 2.5)
  lines(time, nsh_ci[2,121:140], lty = 2, lwd = 2)
  points(time, nsh_ci[2,121:140], col = 6, pch=19, cex = 2.35)

legend("topleft",legend=c("Observed Gloeo","Predicted Gloeo", "95% CI"),col=c(3,6, 5),pch = 19, cex = 2, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('SOTF_',model_name,'_Obs_vs_pred2015_data2015.pdf'))),type = "pdf", dpi = 600) #, width = 8.5, height = 11)

```

## Observed vs. Predicted plots
```{r}

hc_ci <-  ci
nb_ci <-  ci
nsh_ci <-  ci

fitHC <- lm(gloeo$hc_gloeo_ln[121:140] ~ mean_pred_log_hc)
summary(fitHC)

fitHC_SOTF <- lm(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_hc)
summary(fitHC_SOTF)

fitNB <- lm(gloeo$nb_gloeo_ln[121:140] ~ mean_pred_log_nb)
summary(fitNB)

fitNB_SOTF <- lm(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_nb)
summary(fitNB_SOTF)

fitNSH <- lm(gloeo$nsh_gloeo_ln[121:140] ~ mean_pred_log_nsh)
summary(fitNSH)

fitNSH_SOTF <- lm(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_nsh)
summary(fitNSH_SOTF)


# Save output for each site with initial, parameter, and process uncertainty
N.IPDE_hc <- N.IPDE
N.IPDE_nb <- N.IPDE
N.IPDE_nsh <- N.IPDE

# Same for fichter

N.IPDE_hc_f <- N.IPDE
N.IPDE_nb_f <- N.IPDE
N.IPDE_nsh_f <- N.IPDE

#calculate RMSE for each site
obs_log_hc <- gloeo$hc_gloeo_ln[121:140]
obs_log_nb <- gloeo$nb_gloeo_ln[121:140]
obs_log_nsh <- gloeo$nsh_gloeo_ln[121:140]

#calculate RMSE for Fichter
obs_log_sotf <- gloeo$sotf_gloeo_ln[121:140]

mean_pred_log_hc <- colMeans(N.IPDE_hc)
mean_pred_log_nb <- colMeans(N.IPDE_nb)
mean_pred_log_nsh <- colMeans(N.IPDE_nsh)

#fichter
mean_pred_log_hc_f <- colMeans(N.IPDE_hc_f)
mean_pred_log_nb_f <- colMeans(N.IPDE_nb_f)
mean_pred_log_nsh_f <- colMeans(N.IPDE_nsh_f)


RMSE_hc <- round(sqrt(mean((mean_pred_log_hc - obs_log_hc)^2, na.rm = T)),2)
RMSE_nb <- round(sqrt(mean((mean_pred_log_nb - obs_log_nb)^2, na.rm = T)),2)
RMSE_nsh <- round(sqrt(mean((mean_pred_log_nsh - obs_log_nsh)^2, na.rm = T)),2)

# with Fichter
RMSE_hc_f <- round(sqrt(mean((mean_pred_log_hc_f - obs_log_sotf)^2, na.rm = T)),2)
RMSE_nb_f <- round(sqrt(mean((mean_pred_log_nb_f - obs_log_sotf)^2, na.rm = T)),2)
RMSE_nsh_f <- round(sqrt(mean((mean_pred_log_nsh_f - obs_log_sotf)^2, na.rm = T)),2)

#HC
plot(gloeo$hc_gloeo_ln[121:140] ~ mean_pred_log_hc,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "Herrick Cove")
abline(fitHC, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 1.45"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('HC_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5

#HC SOTF
plot(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_hc_f,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "South of the Fells \n with Herrick Cove Model")
abline(fitHC_SOTF, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 1.24"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('HC_F_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5


#NB
plot(gloeo$nb_gloeo_ln[121:140] ~ mean_pred_log_nb,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "Newbury")
abline(fitNB, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 1.82"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('NB_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5

#NB SOTF
plot(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_nb_f,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "South of the Fells \n with Newbury Model")
abline(fitNB_SOTF, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 1.37"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('NB_F_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5

#NSH
plot(gloeo$nsh_gloeo_ln[121:140] ~ mean_pred_log_nsh,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "North Sunapee Harbor")
abline(fitNSH, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 1.39"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('NSH_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5

#NSH SOTF
plot(gloeo$sotf_gloeo_ln[121:140] ~ mean_pred_log_nsh_f,
     pch=19,cex=2.5, col = 3,
     ylim=c(-5.2,0.2), xlim=c(-5.2,0.2), 
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.25,
     cex.main = 2.25,
     ylab="Observed Log G. echinulata (colonies/L)", xlab = "Predicted Log G. echinulata (colonies/L)", 
     main = "South of the Fells \n with North Sunapee Harbor Model")
abline(fitNSH_SOTF, lwd = 3.5, col = 5)
abline(0,1,col=1,lwd=2.5, lty = 2)
#lines(gloeo$hc_gloeo_ln[121:140], hc_ci[2,121:140], lty = 2)
legend("bottomright", legend = c('1:1','Regression Fit',"RMSE = 2.03"),col=c(1, 5, 3), lty =c(2,1,1), lwd = 4, cex = 1.5, bty = "n")

quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0('NSH_F_reg.pdf'))), type = "pdf", dpi = 600) #, width = 11, height = 8.5


```

## Forward Simulation

```{r, echo=FALSE}
### settings
Nmc = 7500         ## set number of Monte Carlo draws 1000
ylim = range(ci,na.rm=TRUE)  ## set Y range on plot
N.cols <- c("black","red","green","blue","orange") ## set colors
trans <- 0.8       ## set transparency
time = 1:140    ## total time
time1 = 1:120       ## calibration period
time2 = 121:140   ## forecast period
```

Before we get started with prediction, let's focus in on a single site to make the task a bit simpler. Because we'll want to display this site for all the different model runs we do let's create a simple function to encapsulate making the plot rather than cluttering our code with constant cut-and-paste redundancy.

# Model site plot function
```{r}
plot.run <- function(){
 # sel = seq(s,ncol(ci),by=NS) # add a sequence to avoid overplotting
  plot(time,time,type='n',ylim=ylim,ylab="LN Gloeo", xlab = "Week")
  ecoforecastR::ciEnvelope(time1,ci[1,1:120],ci[3,1:120],col=col.alpha(5,0.5))
  lines(time1,ci[2,1:120], lty = 2)
  points(time1,ci[2,1:120],pch=19,cex=1.25, col = 6)
 # points(time1,ci[2,1:120],cex = 1)
}

plot.run()
```

# Model site plot function - nice figs

```{r}

plot.run.figs <- function(){
 # sel = seq(s,ncol(ci),by=NS) # add a sequence to avoid overplotting
  plot(time,time,type='n',ylim=ylim,
      xaxt = "n",
     las = 1,
     bty = "l",
     cex.axis = 1.5,
     cex.lab = 1.5,
     cex.main = 2.5,
     ylab="", xlab = "",  #Log G. echinulata (colonies/L)
     main = "Herrick Cove")
  ecoforecastR::ciEnvelope(time1,ci[1,1:120],ci[3,1:120],col=col.alpha(5,0.5))
  lines(time1,ci[2,1:120], lty = 2, lwd = 2)
  points(time1,ci[2,1:120],pch=19,cex=1.35, col = 6)
 # points(time1,ci[2,1:120],cex = 1)
}

plot.run.figs()

```

# Fichter plot fuction
```{r}

#  Check ylim
ylim = c(-7.008481, 4) ## set Y range on plot - too short for NSH

plot.run <- function(){
 # sel = seq(s,ncol(ci),by=NS) # add a sequence to avoid overplotting
  plot(time,time,type='n',ylim=ylim,ylab="LN Gloeo", xlab = "Week")
  #ecoforecastR::ciEnvelope(time1,ci[1,1:120],ci[3,1:120],col=col.alpha(5,0.5))
  lines(time1,gloeo$sotf_gloeo_ln[1:120])
  points(time1,gloeo$sotf_gloeo_ln[1:120],pch=19,cex=1.25, col = 3)
  points(time1,gloeo$sotf_gloeo_ln[1:120],cex = 1)
}

plot.run()
```

### Fill in missing data for known covariates
- calculate weekly mean of min water temp @ all sites EXCEPT fichter
- cross-site variance for weekly differences
```{r}

missing1 <- which(is.na(hindcast_data$covar1))

missing2 <- which(is.na(hindcast_data$covar2)) # no missing data for covar2

# Fill missing holes with data from week_avg1 at same time
for (m in 1:length(missing1)){
        hindcast_data$covar1[missing1[m]] <- hindcast_data$week_avg1[missing1[m]]
        }


```

### Read in Fichter covariate data
```{r}
# Read in covariate 1 (min water temp)  data
    Temp_all <- read_csv("./00_Data_files/Bayesian_model_input_data/wtrtemp_min_AllSites.csv") %>%
      select(year, season_week, SOTF.tempC_min)  %>%  # SELECT SITE HCS.tempC_min
      filter(year < 2016) # use known driver data

    #center covariate data
    Temp_all$SOTF.tempC_min_stand <- (Temp_all$SOTF.tempC_min - mean(Temp_all$SOTF.tempC_min, na.rm = TRUE))/sd(Temp_all$SOTF.tempC_min, na.rm = TRUE)

    Temp <- Temp_all$SOTF.tempC_min_stand
    
    
# Read in covariate 2 air temp GDD data
    GDD_all <- read_csv("./00_Data_files/Bayesian_model_input_data/PRISM_airtemp_GDD_2009-2016.csv") %>%
      select(year, season_week, gdd_sotf_sum)  %>% #SELECT SITE
      filter(year < 2016) #use known driver data for 2015

    #standardize within year to account for different start dates in different years
    # convert to wide first
    GDD_wide <- GDD_all %>%
      pivot_wider(1:3, names_from = season_week, values_from = gdd_sotf_sum)

    GDD_stand <- apply(GDD_wide[,-1],1,function(x) {(x-mean(x,na.rm = TRUE))/sd(x, na.rm = TRUE)})

    #standardize across years
    GDD_stand_yr <- (GDD_stand - mean(GDD_stand, na.rm = TRUE))/sd(GDD_stand, na.rm = TRUE)

    #transpose - to make full wide and then convert back to full long
    GDD_trans <- t(GDD_stand_yr)

    GDD_long <- as.data.frame(GDD_trans) %>%
      pivot_longer(cols = 1:20, names_to = "season_week", values_to = "gdd_sum", names_transform = list(season_week = as.integer)) %>%
      #  mutate(year = rep(2009:2014,times = 1, each = 20)) %>%
      #  mutate(season_weeks = c(1:120)) %>%
      select(gdd_sum)

    GDD <- GDD_long$gdd_sum
```

### Fill in missing data for Fichter known covariates

```{r}

missing1 <- which(is.na(Temp))

# Fill missing holes with data from week_avg1 at same time
for (m in 1:length(missing1)){
        Temp[missing1[m]] <- hindcast_data$week_avg1[missing1[m]]
        }


```


### Forward simulation Forecast Function with same site known covariate data
```{r}

## initial conditions
IC <- as.matrix(mus)

forecastN <- function(IC,params,n=Nmc){

  forecast_time <- 20 # 20 season weeks = 1 year gloeo data

  proc.model <- matrix(NA, n, forecast_time) # storage
  out <- matrix(NA, n, forecast_time) # storage

  gloeo_prev <- IC          ## initialize

  for(t in 1:length(time2)){ # start for last 2 years
    #covar model
      #  covar1 <- covar_hindcast$covar1[t] # hindcasted covariates
      #  covar2 <- covar_hindcast$covar2[t]
    covar1 <- hindcast_data$covar1[t] #known covars with missing data filled in
    covar2 <- hindcast_data$covar2[t]
    #process model
   gloeo_temp = params$beta1 + params$beta2*gloeo_prev + params$beta3*covar1 + params$beta4*covar2 + params$beta5*covar2^2 
    
   proc.model[,t] = rnorm(n,gloeo_temp,params$sd_proc) 
    
   #data model
    out[,t] = rnorm(n,proc.model[,t],params$sd_obs)      ## predict next step with data model
    gloeo_prev <- out[,t]                                 ## update IC
  }
  return(out)
  }

```

### FICHTER Forward simulation Forecast Function with Fichter known covariate driver data
```{r}

## initial conditions
IC <- as.matrix(mus)

forecastN_SOTF <- function(IC,params,n=Nmc){

  forecast_time <- 20 # 20 season weeks = 1 year gloeo data

  proc.model <- matrix(NA, n, forecast_time) # storage
  out <- matrix(NA, n, forecast_time) # storage

  gloeo_prev <- IC          ## initialize

  for(t in 1:length(time2)){ # start for last 2 years
    #covar model
      #  covar1 <- covar_hindcast$covar1[t] # hindcasted covariates
      #  covar2 <- covar_hindcast$covar2[t]
    covar1 <- Temp[t] #known covars with missing data filled in
    covar2 <- GDD[t]
    #process model
   gloeo_temp = params$beta1 + params$beta2*gloeo_prev + params$beta3*covar1 + params$beta4*covar2 + params$beta5*covar2^2 
    
   proc.model[,t] = rnorm(n,gloeo_temp,params$sd_proc) 
    
   #data model
    out[,t] = rnorm(n,proc.model[,t],params$sd_obs)      ## predict next step with data model
    gloeo_prev <- out[,t]                                 ## update IC
  }
  return(out)
  }

```


Our next goal in making a forecast is to run the model forward under it's 'default' values, which we'll take as the mean of the various inputs. To help us out let's make another function that encapsulates our model and generalizes it for the different cases we'll need. This code is directly analogous to the process model in the earlier JAGS code, and we don't need to replicate the data or parameter models.

To make a deterministic prediction, we'd then want to calculate the means of all of our different inputs and pass these means to our model. Since there run is deterministic, we only need to run it once (n=1)

### Deterministic prediction
```{r}
posteriors = out
n = 1 # just run once

# Deterministic = parameters set to mean
params.det <- list(sd_obs = 0, sd_proc = 0, beta1 = mean(posteriors[,grep("beta1",colnames(posteriors))],na.rm = TRUE),
                     beta2 = mean(posteriors[,grep("beta2",colnames(posteriors))],na.rm = TRUE), beta3 = mean(posteriors[,grep("beta3",colnames(posteriors))],na.rm = TRUE),
                     beta4 = mean(posteriors[,grep("beta4",colnames(posteriors))],na.rm = TRUE),beta5 = mean(posteriors[,grep("beta5",colnames(posteriors))],na.rm = TRUE),sd_C1 = 0, sd_C2 = 0)

N.det <- forecastN(IC = mean(IC[,"mu[120]"]),  ## mean of IC
                 params = params.det,
                 n=1)
  
## Plot run
plot.run()
lines(time2,N.det,col="purple",lwd=3)

write.csv(N.det,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_det.prediction','.csv'))),row.names = FALSE)

```

### Deterministic prediction - SOTF
```{r}
posteriors = out
n = 1 # just run once

# Deterministic = parameters set to mean
params.det <- list(sd_obs = 0, sd_proc = 0, beta1 = mean(posteriors[,grep("beta1",colnames(posteriors))],na.rm = TRUE),
                     beta2 = mean(posteriors[,grep("beta2",colnames(posteriors))],na.rm = TRUE), beta3 = mean(posteriors[,grep("beta3",colnames(posteriors))],na.rm = TRUE),
                     beta4 = mean(posteriors[,grep("beta4",colnames(posteriors))],na.rm = TRUE),beta5 = mean(posteriors[,grep("beta5",colnames(posteriors))],na.rm = TRUE),sd_C1 = 0, sd_C2 = 0)

N.det <- forecastN_SOTF(IC = mean(IC[,"mu[120]"]),  ## mean of IC
                 params = params.det,
                 n=1)
  
## Plot run
plot.run()
lines(time2,N.det,col="purple",lwd=3)

write.csv(N.det,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_det.prediction_','SOTF','.csv'))),row.names = FALSE)

```


# Monte Carlo Error Propagation

For each source of uncertainty we'll be exploring the Monte Carlo approach to error propagation. Let's start with the initial condition uncertainty. For this set of runs we'll want to continue to hold all the parameters and drivers at their means, and keep the process error off, but we'll vary the initial conditions. Specifically, we'll run the model `r Nmc` times, and each time we run the model we'll start from a different initial condition. For this analysis the distribution of initial conditions that we want to sample from is just the posterior distribution of the population size at our focal site in the last year of the calibration period, `N[6,30]`. Because we know that posterior distributions often have covariances among parameters, we're going to sample the _row numbers_ in the MCMC output rather than sample the posterior state directly. We'll save these row numbers and use the same rows when we later sample the model parameters, process error, and random effects as well. While we had the benefit of the posterior state estimate here, in other contexts the initial condition uncertainty might be derived directly from field sampled data, or (for unmeasured sites) may require another statistical model to make a _spatial_ prediction of the state of the system to new locations. If we're particularly data limited we may have to rely on Bayesian priors to inform the initial conditions (e.g. through expert elicitation).

### Initial Condition uncertainty
```{r}
## sample parameter rows from previous analysis
#prow = sample.int(nrow(params),Nmc,replace=TRUE)

Nmc = 7500
prow = sample.int(nrow(params_init),Nmc,replace=TRUE) #sample parameter rows

N.I <- forecastN(IC = IC[prow,"mu[120]"],  ## sample IC
                 params = params.det,
                 n=Nmc)

## Plot run
plot.run()
N.I.ci = apply(N.I,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.I,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC','.csv'))),row.names = FALSE)

```

### Initial Condition uncertainty - SOTF
```{r}
## sample parameter rows from previous analysis
#prow = sample.int(nrow(params),Nmc,replace=TRUE)

Nmc = 7500
prow = sample.int(nrow(params_init),Nmc,replace=TRUE) #sample parameter rows

N.I <- forecastN_SOTF(IC = IC[prow,"mu[120]"],  ## sample IC
                 params = params.det,
                 n=Nmc)

## Plot run
plot.run()
N.I.ci = apply(N.I,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.I,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC_','SOTF','.csv'))),row.names = FALSE)

```

### Parameter uncertainty

```{r}
prow = sample.int(nrow(params_init),Nmc,replace=TRUE) #sample parameter rows

params.ip <- list(sd_obs = 0, sd_proc = 0, beta1 = posteriors[prow,"beta1"],
                     beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], beta4 = posteriors[prow,"beta4"],
                     beta5 = posteriors[prow,"beta5"],sd_C1 = 0) #dropped from model, sd_C2 = 0)
 
N.IP <- forecastN(IC = IC[prow,"mu[120]"],
                  params = params.ip,
                  n = Nmc)


## Plot run
plot.run()
N.IP.ci = apply(N.IP,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IP,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa','.csv'))),row.names = FALSE)

```

### Parameter uncertainty - SOTF

```{r}
prow = sample.int(nrow(params_init),Nmc,replace=TRUE) #sample parameter rows

params.ip <- list(sd_obs = 0, sd_proc = 0, beta1 = posteriors[prow,"beta1"],
                     beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], beta4 = posteriors[prow,"beta4"],
                     beta5 = posteriors[prow,"beta5"],sd_C1 = 0) #dropped from model, sd_C2 = 0)
 
N.IP <- forecastN_SOTF(IC = IC[prow,"mu[120]"],
                  params = params.ip,
                  n = Nmc)


## Plot run
plot.run()
N.IP.ci = apply(N.IP,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IP,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa_','SOTF','.csv'))),row.names = FALSE)

```

### Driver uncertainty

Within our forecast precipitation is the primary extrinsic driver, and thus to make a forecast of our population we need to be able to make a forecast of this driver as well. Here we're going to rely on a `NE` member ensemble of precipitation forecasts, and as you can see the uncertainty in this forecasts grows with time.

```{r,echo=FALSE}
# plot(time2,ppt_ensemble[1,],type='n',ylim=range(ppt_ensemble),xlab="time",ylab="precipitation (mm)")
# for(i in 1:NE){
#   lines(time2,ppt_ensemble[i,],lwd=0.5,col="grey")
# }
```

This example of having a smaller number of driver ensembles is not uncommon, and we can handle this easily by resampling _with replacement_ the ensemble members (again, represented as row numbers) the same number of times as our overall ensembles. Thus, while every run may have a unique initial condition and parameter combination, many runs share the same drivers.

When driving ecological forecasts with other forecast outputs (weather, land use, economics, etc), it is important to remember that we can only resample **predictions** or we can sample ensemble members **within a projection**, but we CANNOT resample **across projections**. For example, if I have a given climate scenario (e.g. RCP4.5), I can resample over what different climate models predict, but I cannot resample or average across the different scenarios (e.g. RCP4.5 and 8.5), because those scenarios themselves do not represent random draws from the distribution of possible futures.


**Currently same as parameter uncertainty** - need to include covariate ensembles
```{r}

params.ipd <- list(sd_obs = 0, sd_proc = 0, beta1 = posteriors[prow,"beta1"],
              beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], beta4 = posteriors[prow,"beta4"], 
              beta5 = posteriors[prow,"beta5"],
              sd_C1 = 1/sqrt(posteriors[prow,"tau_C1_proc"])) #, sd_C2 = 1/sqrt(posteriors[prow,"tau_C2_proc"])) dropped from model


N.IPD <- forecastN(IC = IC[prow,"mu[120]"],
                  params = params.ipd,
                  n = Nmc)

## Plot run
plot.run()
N.IPD.ci = apply(N.IPD,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans)) # driver
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans)) # parameter
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans)) # IC
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IPD,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa.D_','.csv'))),row.names = FALSE)

```

### Process uncertainty

Adding process error to the model looks similar to both older _stochastic_ modeling approaches and to the _residual_ error in statistical models. However, it is subtly distinct in a few important ways. First, unlike theoretical stochastic models, process error is estimated explicitly by fitting models to data. Second, unlike residual error, when we estimate process error we partition it from the observation error. Thus the process error represents things in the process that the model is unable to capture (which will always occur because all models are approximations). The distinction between process and observation error is important because observation error only affects the current observation, but process error propagates into the future.

```{r}
## process error samples
params.ipde <- list(sd_obs = 0, sd_proc = 1/sqrt(posteriors[prow,"tau_proc"]), ## convert from precision to standard deviation
               beta1 = posteriors[prow,"beta1"],beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], 
               beta4 = posteriors[prow,"beta4"], beta5 = posteriors[prow,"beta5"],
               sd_C1 = 1/sqrt(posteriors[prow,"tau_C1_proc"])) #, sd_C2 = 1/sqrt(posteriors[prow,"tau_C2_proc"]))


N.IPDE <- forecastN(IC = IC[prow,"mu[120]"],
                  params = params.ipde,
                  n = Nmc)

## Plot run
plot.run()
#plot.run.figs()
N.IPDE.ci = apply(N.IPDE,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

#No driver
legend("topleft",legend=c("Process","Parameter","Initial Conditions"),col=c(4, 2, 1),lty=1,lwd=5, bty = "n")

#legend("topleft",legend=c("Process","Driver","Parameter","InitCond"),col=rev(N.cols[-5]),lty=1,lwd=5)

write.csv(N.IPDE,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa.D.P','.csv'))),row.names = FALSE)

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_TS_pred2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)
# 
# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_vs_pred2015.pdf'))), type = "pdf", dpi = 600, width = 11, height = 8.5)


```

### Process uncertainty - SOTF

```{r}
## process error samples
params.ipde <- list(sd_obs = 0, sd_proc = 1/sqrt(posteriors[prow,"tau_proc"]), ## convert from precision to standard deviation
               beta1 = posteriors[prow,"beta1"],beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], 
               beta4 = posteriors[prow,"beta4"], beta5 = posteriors[prow,"beta5"],
               sd_C1 = 1/sqrt(posteriors[prow,"tau_C1_proc"])) #, sd_C2 = 1/sqrt(posteriors[prow,"tau_C2_proc"]))


N.IPDE <- forecastN_SOTF(IC = IC[prow,"mu[120]"],
                  params = params.ipde,
                  n = Nmc)

## Plot run
plot.run()
N.IPDE.ci = apply(N.IPDE,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IPDE,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa.D.P_','SOTF', '.csv'))),row.names = FALSE)

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_SOTF', '_TS_pred2015.png'))), type = "png")

```

### Observation Uncertainty
```{r}
params.ipdeo <- list(sd_obs = 1/sqrt(posteriors[prow,"tau_obs"]), sd_proc = 1/sqrt(posteriors[prow,"tau_proc"]), 
                     beta1 = posteriors[prow,"beta1"],beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], 
                     beta4 = posteriors[prow,"beta4"], beta5 = posteriors[prow,"beta5"],
                     sd_C1 = 1/sqrt(posteriors[prow,"tau_C1_proc"])) #, sd_C2 = 1/sqrt(posteriors[prow,"tau_C2_proc"]))


N.IPDEO <- forecastN(IC = IC[prow,"mu[120]"],
                  params = params.ipdeo,
                  n = Nmc)

## Plot run
plot.run()
N.IPDEO.ci = apply(N.IPDEO,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDEO[1,],N.IPDEO[3,],col=col.alpha(N.cols[5],trans))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans)) no driver uncertainty
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IPDEO,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa.D.P.O','.csv'))),row.names = FALSE)

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_pred2015.png'))), type = "png")
```

### Observation Uncertainty - SOTF
```{r}
params.ipdeo <- list(sd_obs = 1/sqrt(posteriors[prow,"tau_obs"]), sd_proc = 1/sqrt(posteriors[prow,"tau_proc"]), 
                     beta1 = posteriors[prow,"beta1"],beta2 = posteriors[prow,"beta2"], beta3 = posteriors[prow,"beta3"], 
                     beta4 = posteriors[prow,"beta4"], beta5 = posteriors[prow,"beta5"],
                     sd_C1 = 1/sqrt(posteriors[prow,"tau_C1_proc"])) #, sd_C2 = 1/sqrt(posteriors[prow,"tau_C2_proc"]))


N.IPDEO <- forecastN_SOTF(IC = IC[prow,"mu[120]"],
                  params = params.ipdeo,
                  n = Nmc)

## Plot run
plot.run()
N.IPDEO.ci = apply(N.IPDEO,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDEO[1,],N.IPDEO[3,],col=col.alpha(N.cols[5],trans))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
#ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans)) no driver uncertainty
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)

write.csv(N.IPDEO,file=file.path(paste("./5_Model_output/5.2_Hindcasting/",paste0(model_name,'_hindcast.IC.Pa.D.P.O_','SOTF','.csv'))),row.names = FALSE)

# quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name,'_Obs_pred2015.png'))), type = "png")
```


### Random Effect uncertainty

The last figure above represent our best forecast if we're making an **in-sample** prediction (i.e. forecasting one of the sites that we have previously studied). However, if we are making an **out-of-sample** prediction to a new site then there is an additional source of uncertainty that needs to be considered -- the unexplained site-to-site variability being captured by the random effect. When we're making an in-sample prediction we use the posterior $\alpha$ associated with that specific site, but for a new site we need to move up a level in the hierarchical model and sample new alpha values using the across-site precision, $\tau_{site}$. While the out-of-sample forecast is going to have greater uncertainty (which makes intuitive sense and is a desirable feature), there's no guarantee that the in-sample prediction is within the predictive interval of the out-of-sample prediction because the focal site might have been above- or below-average relative to the across-site mean.

```{r}
## Random effect samples
tau.mc <- 1/sqrt(params[prow,"tau_site"]) ## convert from precision to std deviation
aNew.mc <- rnorm(Nmc,0,tau.mc)            ## draw out-of-sample predictions of alpha at a new site

N.IPDEA <- forecastN(IC=IC[prow,"N[6,30]"],    ## sample IC
                   ppt=ppt_ensemble[drow,],    ## Sample drivers
                   r=params[prow,"r_global"],  ## sample parameters
                   Kg=params[prow,"K_global"],
                   beta=params[prow,"beta"],
                   alpha=aNew.mc,              ## sample random effect
                   Q=Qmc,                      ## process error
                   n=Nmc)

## Plot run
plot.run()
N.IPDEA.ci = apply(N.IPDEA,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDEA.ci[1,],N.IPDEA.ci[3,],col=col.alpha(N.cols[5],trans))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)
```

**Question 5:** The last step added random effects, but this uncertainty could be further partitioned into two parts: the ecological site-to-site variability in the population processes, and the parameter uncertainty about the site-to-site variance. To partition these out repeat this analysis setting `tau.mc` to its posterior mean. How does this change your results? How much of the random effect uncertainty is due to ecological variability versus uncertainty about `tau.mc`?

```{r}
## Random effect samples with ecological variability vs. tau.mc
tau.mc <- 1/sqrt(params[prow,"tau_site"]) ## convert from precision to std deviation
tau.mc <- param.mean["tau_site"]
aNew.mc <- rnorm(Nmc,0,tau.mc)            ## draw out-of-sample predictions of alpha at a new site

N.IPDEA <- forecastN(IC=IC[prow,"N[6,30]"],    ## sample IC
                   ppt=ppt_ensemble[drow,],    ## Sample drivers
                   r=params[prow,"r_global"],  ## sample parameters
                   Kg=params[prow,"K_global"],
                   beta=params[prow,"beta"],
                   alpha=aNew.mc,              ## sample random effect
                   Q=Qmc,                      ## process error
                   n=Nmc)

## Plot run
plot.run()
N.IPDEA.ci = apply(N.IPDEA,2,quantile,c(0.025,0.5,0.975))
ecoforecastR::ciEnvelope(time2,N.IPDEA.ci[1,],N.IPDEA.ci[3,],col=col.alpha(N.cols[5],trans))
ecoforecastR::ciEnvelope(time2,N.IPDE.ci[1,],N.IPDE.ci[3,],col=col.alpha(N.cols[4],trans))
ecoforecastR::ciEnvelope(time2,N.IPD.ci[1,],N.IPD.ci[3,],col=col.alpha(N.cols[3],trans))
ecoforecastR::ciEnvelope(time2,N.IP.ci[1,],N.IP.ci[3,],col=col.alpha(N.cols[2],trans))
ecoforecastR::ciEnvelope(time2,N.I.ci[1,],N.I.ci[3,],col=col.alpha(N.cols[1],trans))
lines(time2,N.I.ci[2,],lwd=0.5)
```


# Uncertainty Analysis

Our final analysis is focused on quantifying the relative contributions of each of the 5 uncertainty terms to the overall predictive variance, and how that partitioning changes with time. To do this we will calculate the variances, because unlike predictive intervals or standard errors variances combine additively.

```{r}
### calculation of variances
varI     <- apply(N.I,2,var)
varIP    <- apply(N.IP,2,var)
#varIPD   <- apply(N.IPD,2,var)
varIPDE  <- apply(N.IPDE,2,var)
#varIPDEA <- apply(N.IPDEA,2,var) #dropped
#varMat   <- rbind(varI,varIP,varIPD,varIPDE,varIPDEA)
#varMat   <- rbind(varI,varIP,varIPD,varIPDE)
varMat   <- rbind(varI,varIP,varIPDE)

# ## out-of-sample stacked area plot
# V.pred.rel <- apply(varMat,2,function(x) {x/max(x)})
# plot(time2,V.pred.rel[1,],ylim=c(0,1),type='n',main="Relative Variance: Out-of-Sample",ylab="Proportion of Variance",xlab="time")
# ciEnvelope(time2,rep(0,ncol(V.pred.rel)),V.pred.rel[1,],col=N.cols[1])
# ciEnvelope(time2,V.pred.rel[1,],V.pred.rel[2,],col=N.cols[2])
# ciEnvelope(time2,V.pred.rel[2,],V.pred.rel[3,],col=N.cols[3])
# ciEnvelope(time2,V.pred.rel[3,],V.pred.rel[4,],col=N.cols[4])
# ciEnvelope(time2,V.pred.rel[4,],V.pred.rel[5,],col=N.cols[5])
# legend("topleft",legend=c("RandomEffect","Process","Driver","Parameter","InitCond"),col=rev(N.cols),lty=1,lwd=5)

## in-sample stacked area plot
#V.pred.rel.in <- apply(varMat[-5,],2,function(x) {x/max(x)})
V.pred.rel.in <- apply(varMat,2,function(x) {x/max(x)})

plot(time2,V.pred.rel.in[1,],ylim=c(0,1),type='n',main="Relative Variance: In-Sample",ylab="Proportion of Variance",xlab="time")
ciEnvelope(time2,rep(0,ncol(V.pred.rel.in)),V.pred.rel.in[1,],col=N.cols[1])
ciEnvelope(time2,V.pred.rel.in[1,],V.pred.rel.in[2,],col=N.cols[2])
ciEnvelope(time2,V.pred.rel.in[2,],V.pred.rel.in[3,],col=N.cols[4]) # skip driver
#ciEnvelope(time2,V.pred.rel.in[3,],V.pred.rel.in[4,],col=N.cols[4]) 
legend("topleft",legend=c("Process","Driver","Parameter","InitCond"),col=rev(N.cols[-5]),lty=1,lwd=5)


quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name, '_Prop_pred2015.png'))), type = "png")

# Fichter
quartz.save(file = file.path(paste("~/Documents/Gloeo Bayesian Modeling/R Output/Hindcasting_Figures/", paste0(model_name, '_SOTF','_Prop_pred2015.png'))), type = "png")


```

